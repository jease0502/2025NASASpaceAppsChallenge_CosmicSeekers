import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import joblib
import warnings
import os
import json
import time

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from lightgbm import LGBMClassifier

# --- ç’°å¢ƒè¨­å®š ---
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)
sns.set_style("whitegrid")
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Heiti TC', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

# --- çµ„æ…‹è¨­å®š (Configuration) ---
class Config:
    """
    é›†ä¸­ç®¡ç†æ‰€æœ‰è¶…åƒæ•¸å’Œè¨­å®šã€‚
    """
    # --- 1. æª”æ¡ˆèˆ‡è·¯å¾‘è¨­å®š ---
    CSV_FILE_PATH = "exoplanet_data_processed.csv"
    MODEL_DIR = "model"

    # --- 2. è³‡æ–™åˆ†å‰²è¨­å®š ---
    TEST_SIZE = 0.3
    RANDOM_STATE = 42

    # --- 3. GridSearchCV è¶…åƒæ•¸ç¶²æ ¼è¨­å®š ---
    # âœ¨ MODIFICATION: å¾å›ºå®šåƒæ•¸æ”¹ç‚ºæœå°‹ç¶²æ ¼
    # è­¦å‘Šï¼šç¶²æ ¼è¶Šå¤§ï¼Œæœå°‹æ™‚é–“è¶Šé•·ï¼ä»¥ä¸‹æ˜¯ä¾›å¿«é€Ÿæ¸¬è©¦ç”¨çš„å°ç¶²æ ¼ã€‚
    PARAM_GRIDS = {
        "LogisticRegression": {
            "C": [0.1, 1.0],
            "solver": ["saga"],
            "max_iter": [3000],
            "multi_class": ["multinomial"],
            "penalty": ["l2"]
        },
        "RandomForest": {
            "n_estimators": [500],
            "max_depth": [10, None],
            "min_samples_split": [5],
            "class_weight": ["balanced"]
        },
        "GradientBoosting": {
            "n_estimators": [500],
            "learning_rate": [0.1],
            "max_depth": [5],
            "subsample": [0.8]
        },
        "LightGBM": {
            "n_estimators": [1000],
            "learning_rate": [0.1],
            "num_leaves": [31],
            "max_depth": [7],
            "class_weight": ["balanced"],
            "boosting_type": ["gbdt"]
        }
    }

    # å»ºç«‹æ¨¡å‹å¯¦ä¾‹ (ä¸å¸¶åƒæ•¸ï¼Œåƒæ•¸ç”± GridSearch æä¾›)
    MODELS_TO_TUNE = {
        "LogisticRegression": LogisticRegression(random_state=RANDOM_STATE, class_weight='balanced'),
        "RandomForest": RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced'),
        "GradientBoosting": GradientBoostingClassifier(random_state=RANDOM_STATE),
        "LightGBM": LGBMClassifier(random_state=RANDOM_STATE, verbosity=-1, class_weight='balanced')
    }
    
    # GridSearch çš„è¨­å®š
    CV_FOLDS = 5  # äº¤å‰é©—è­‰æŠ˜æ•¸ (5æŠ˜é€šå¸¸æ˜¯å€‹å¥½èµ·é»)
    # ä½¿ç”¨ macro-averaged F1-scoreï¼Œé©åˆå¤šåˆ†é¡å•é¡Œ
    GRID_SEARCH_SCORING_METRIC = 'f1_macro'

    # --- 4. æ¨¡å‹è§£é‡‹èˆ‡å ±å‘Šè¨­å®š ---
    N_FEATURES_TO_DISPLAY = 20
    SHAP_SAMPLE_SIZE = 100
    N_TOP_CANDIDATES = 20


class ExoplanetDataProcessor:
    # (æ­¤é¡åˆ¥å…§å®¹èˆ‡å‰ä¸€ç‰ˆç›¸åŒï¼Œä¿æŒä¸è®Š)
    def __init__(self, file_path):
        self.file_path = file_path
        self.df = None
        self.X_train_scaled = None
        self.X_test_scaled = None
        self.y_train = None
        self.y_test = None
        self.feature_names = None
        self.scaler = None
        self.imputer = None
        self.candidate_df_processed = None
        self.candidate_info = None

    def load_data(self):
        try:
            self.df = pd.read_csv(self.file_path, dtype={'source_id': str})
            print(f"âœ… æˆåŠŸè¼‰å…¥è³‡æ–™ '{self.file_path}'ã€‚")
            return True
        except FileNotFoundError:
            print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ '{self.file_path}'ã€‚è«‹å…ˆåŸ·è¡Œ data_preprocessing_augment.pyã€‚")
            return False

    def prepare_data(self):
        self.df.replace([np.inf, -np.inf], np.nan, inplace=True)
        
        # ä½¿ç”¨æ‰€æœ‰æ•¸æ“šé€²è¡Œè¨“ç·´
        training_df = self.df.copy()
        
        if training_df.empty:
            print("âŒ éŒ¯èª¤ï¼šæ²’æœ‰æ‰¾åˆ°è¨“ç·´è³‡æ–™ã€‚")
            return False
            
        # å°‡ disposition è½‰æ›ç‚ºæ•¸å€¼æ¨™ç±¤
        disposition_map = {
            'CONFIRMED': 2,
            'CANDIDATE': 1,
            'FALSE POSITIVE': 0
        }
        training_df['disposition'] = training_df['disposition'].map(disposition_map)
        
        # ä¿å­˜æ¨™ç±¤æ˜ å°„é—œä¿‚ï¼Œç”¨æ–¼å¾ŒçºŒå ±å‘Š
        self.label_map = {v: k for k, v in disposition_map.items()}
        
        # One-hot encoding for telescope
        training_df = pd.get_dummies(training_df, columns=['source_telescope'], drop_first=True)
        # æå–ç‰¹å¾µå’Œæ¨™ç±¤
        X = training_df.drop(columns=['disposition', 'source_id'])
        y = training_df['disposition']
        self.feature_names = X.columns.tolist()

        # åˆ†å‰²è¨“ç·´é›†å’Œæ¸¬è©¦é›†
        X_train, X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=Config.TEST_SIZE, random_state=Config.RANDOM_STATE, stratify=y
        )

        # æ•¸æ“šé è™•ç†ï¼šç¼ºå¤±å€¼å¡«å……å’Œæ¨™æº–åŒ–
        self.imputer = SimpleImputer(strategy='median')
        X_train_imputed = self.imputer.fit_transform(X_train)
        X_test_imputed = self.imputer.transform(X_test)

        self.scaler = StandardScaler()
        self.X_train_scaled = self.scaler.fit_transform(X_train_imputed)
        self.X_test_scaled = self.scaler.transform(X_test_imputed)

        print("âœ… è¨“ç·´è³‡æ–™é è™•ç†èˆ‡åˆ†å‰²å®Œæˆã€‚")
        print(f"   - è¨“ç·´é›†å¤§å°: {self.X_train_scaled.shape}")
        print(f"   - æ¸¬è©¦é›†å¤§å°: {self.X_test_scaled.shape}")
        print(f"   - é¡åˆ¥åˆ†å¸ƒ: {pd.Series(self.y_train).value_counts().to_dict()}")
        
        return True

    def run(self):
        if self.load_data():
            return self.prepare_data()
        return False


# âœ¨ NEW CLASS: å°ˆé–€ç”¨æ–¼åŸ·è¡Œ GridSearchCV çš„é¡åˆ¥
class HyperparameterTuner:
    def __init__(self, models, param_grids, X_train, y_train):
        self.models = models
        self.param_grids = param_grids
        self.X_train = X_train
        self.y_train = y_train
        self.results = {}

    def tune(self):
        print("\n" + "="*70)
        print("ğŸš€ é–‹å§‹é€²è¡Œ GridSearchCV è¶…åƒæ•¸æœå°‹...")
        print(f"è©•åˆ†æ¨™æº–: '{Config.GRID_SEARCH_SCORING_METRIC}'")
        print("è­¦å‘Šï¼šæ­¤éç¨‹å¯èƒ½éå¸¸è€—æ™‚ï¼")
        print("="*70)
        
        for name, model in self.models.items():
            start_time = time.time()
            print(f"\n--- æ­£åœ¨ç‚º '{name}' é€²è¡Œç¶²æ ¼æœå°‹ ---")
            param_grid = self.param_grids[name]
            
            grid_search = GridSearchCV(
                estimator=model,
                param_grid=param_grid,
                cv=Config.CV_FOLDS,
                scoring=Config.GRID_SEARCH_SCORING_METRIC,
                n_jobs=1,   # æ”¹ç”¨å–®ç·šç¨‹ä»¥é¿å…è¨˜æ†¶é«”å•é¡Œ
                verbose=2,  # é¡¯ç¤ºæ›´è©³ç´°çš„é€²åº¦
                pre_dispatch='2*n_jobs'  # é™åˆ¶ä¸¦è¡Œä½œæ¥­æ•¸é‡
            )
            grid_search.fit(self.X_train, self.y_train)
            
            end_time = time.time()
            duration = end_time - start_time
            
            self.results[name] = {
                "best_estimator": grid_search.best_estimator_,
                "best_params": grid_search.best_params_,
                "best_score": grid_search.best_score_,
                "duration_seconds": duration
            }
            print(f"âœ… '{name}' æœå°‹å®Œæˆï¼Œè€—æ™‚: {duration:.2f} ç§’")
            print(f"   - æœ€ä½³åˆ†æ•¸ ({Config.GRID_SEARCH_SCORING_METRIC}): {grid_search.best_score_:.4f}")
            print(f"   - æœ€ä½³åƒæ•¸: {grid_search.best_params_}")

    def get_best_model(self):
        if not self.results:
            return None, None, -1

        best_model_name = max(self.results, key=lambda name: self.results[name]['best_score'])
        best_result = self.results[best_model_name]
        
        return best_model_name, best_result['best_estimator'], best_result['best_score']


class ModelInterpreter:
    # (æ­¤é¡åˆ¥å…§å®¹èˆ‡å‰ä¸€ç‰ˆç›¸åŒï¼Œä¿æŒä¸è®Š)
    def __init__(self, model, feature_names):
        self.model = model
        self.feature_names = feature_names

    def generate_and_save_feature_importance(self, X_train, y_train, model_path, n_features):
        model_name = self.model.__class__.__name__
        json_filename = os.path.join(model_path, f"{model_name.lower()}_feature_importance.json")
        if hasattr(self.model, 'feature_importances_'):
            importances = self.model.feature_importances_
            total_importance = np.sum(importances)
            normalized_importances = (importances / total_importance) * 100 if total_importance > 0 else importances
            importance_dict = dict(zip(self.feature_names, normalized_importances))
            sorted_importances = sorted(importance_dict.items(), key=lambda item: item[1], reverse=True)
            top_n_importances = {feature: float(score) for feature, score in sorted_importances[:n_features]}
            with open(json_filename, 'w', encoding='utf-8') as f:
                json.dump(top_n_importances, f, ensure_ascii=False, indent=4)
            print(f"   - âœ… å‰ {n_features} åç‰¹å¾µé‡è¦æ€§å·²å„²å­˜è‡³ '{json_filename}'")
            features, scores = list(top_n_importances.keys()), list(top_n_importances.values())
            plt.figure(figsize=(12, 10)); plt.title(f'å‰ {n_features} åç‰¹å¾µé‡è¦æ€§ ({model_name})'); plt.barh(range(len(scores)), scores[::-1], color='dodgerblue'); plt.yticks(range(len(scores)), features[::-1]); plt.xlabel('ç›¸å°é‡è¦æ€§ (%)'); plt.tight_layout(); plt.show()
        else:
            print(f"   - â„¹ï¸ æ¨¡å‹ {model_name} ä¸æ”¯æ´ 'feature_importances_' å±¬æ€§ã€‚")

    def explain_with_shap(self, X_train, y_train, X_test_sample, n_features):
        print(f"\nğŸ”® æ­£åœ¨ç‚º '{self.model.__class__.__name__}' ç”¢ç”Ÿ SHAP è§£é‡‹åœ–...")
        if 'predict_proba' in dir(self.model):
            explainer = shap.KernelExplainer(self.model.predict_proba, X_test_sample)
            shap_values = explainer.shap_values(X_test_sample)
            shap.summary_plot(shap_values[1], X_test_sample, feature_names=self.feature_names, max_display=n_features, show=False)
        else:
            explainer = shap.Explainer(self.model, X_test_sample)
            shap_values = explainer(X_test_sample)
            shap.summary_plot(shap_values, X_test_sample, feature_names=self.feature_names, max_display=n_features, show=False)
        plt.title(f'SHAP ç‰¹å¾µå½±éŸ¿åŠ›åˆ†æ ({self.model.__class__.__name__})', fontsize=16); plt.tight_layout(); plt.show()


# --- ä¸»åŸ·è¡Œæµç¨‹ (å·²é‡æ§‹) ---
if __name__ == "__main__":
    # 1. è³‡æ–™æº–å‚™
    processor = ExoplanetDataProcessor(file_path=Config.CSV_FILE_PATH)
    if not processor.run():
        print("âŒ è³‡æ–™è™•ç†å¤±æ•—ï¼Œç¨‹å¼çµ‚æ­¢ã€‚")
        exit()

    # 2. åŸ·è¡Œè¶…åƒæ•¸ç¶²æ ¼æœå°‹
    tuner = HyperparameterTuner(
        models=Config.MODELS_TO_TUNE,
        param_grids=Config.PARAM_GRIDS,
        X_train=processor.X_train_scaled,
        y_train=processor.y_train
    )
    tuner.tune()
    
    # 3. å–å¾—æœ€ä½³æ¨¡å‹
    best_model_name, best_model, best_score = tuner.get_best_model()

    if best_model is None:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•æœ€ä½³æ¨¡å‹ï¼Œç¨‹å¼çµ‚æ­¢ã€‚")
        exit()

    print("\n" + "="*70)
    print(f"ğŸ† ç¸½å† è»æ¨¡å‹: {best_model_name}")
    print(f"   - æœ€ä½³äº¤å‰é©—è­‰åˆ†æ•¸ ({Config.GRID_SEARCH_SCORING_METRIC}): {best_score:.4f}")
    print(f"   - æœ€ä½³åƒæ•¸: {best_model.get_params()}")
    print("="*70)

    # 4. ä½¿ç”¨æœ€ä½³æ¨¡å‹é€²è¡Œå¾ŒçºŒæ‰€æœ‰åˆ†æ
    # (é¦–å…ˆï¼Œåœ¨å®Œæ•´çš„è¨“ç·´é›†ä¸Šé‡æ–°è¨“ç·´æœ€ä½³æ¨¡å‹)
    print("\nğŸ’¾ æ­£åœ¨å®Œæ•´çš„è¨“ç·´é›†ä¸Šé‡æ–°è¨“ç·´æœ€ä½³æ¨¡å‹ä¸¦å„²å­˜...")
    best_model.fit(processor.X_train_scaled, processor.y_train)
    os.makedirs(Config.MODEL_DIR, exist_ok=True)
    joblib.dump(best_model, os.path.join(Config.MODEL_DIR, f"best_model_{best_model_name.lower()}.joblib"))
    print("   - âœ… æœ€ä½³æ¨¡å‹å·²å„²å­˜ã€‚")
    
    # 5. ç”¢ç”Ÿæœ€ä½³æ¨¡å‹çš„è©•ä¼°å ±å‘Š
    print("\nğŸ“‹ æ­£åœ¨ç‚ºæœ€ä½³æ¨¡å‹ç”Ÿæˆæ¸¬è©¦é›†è©•ä¼°å ±å‘Š...")
    y_pred = best_model.predict(processor.X_test_scaled)
    target_names = ['FALSE POSITIVE', 'CANDIDATE', 'CONFIRMED']
    report = classification_report(processor.y_test, y_pred, target_names=target_names, output_dict=True)
    cm = confusion_matrix(processor.y_test, y_pred)
    model_stats = {
        "model_name": best_model_name,
        "best_cv_score": best_score,
        "best_parameters": best_model.get_params(),
        "test_set_classification_report": report,
        "test_set_confusion_matrix": {"labels": target_names, "matrix": cm.tolist()}
    }
    json_filename = os.path.join(Config.MODEL_DIR, f"best_model_{best_model_name.lower()}_stats.json")
    with open(json_filename, 'w', encoding='utf-8') as f:
        json.dump(model_stats, f, ensure_ascii=False, indent=4)
    print(f"   - âœ… è©•ä¼°å ±å‘Šå·²å„²å­˜è‡³ '{json_filename}'")
    print("\n--- æ¸¬è©¦é›†è¡¨ç¾ ---")
    print(classification_report(processor.y_test, y_pred, target_names=target_names))
    print("-" * 20)

    # 6. é€²è¡Œæ¨¡å‹è§£é‡‹ (Feature Importance & SHAP)
    interpreter = ModelInterpreter(model=best_model, feature_names=processor.feature_names)
    interpreter.generate_and_save_feature_importance(
        processor.X_train_scaled, processor.y_train, Config.MODEL_DIR, Config.N_FEATURES_TO_DISPLAY
    )
    X_test_sample = processor.X_test_scaled[:Config.SHAP_SAMPLE_SIZE]
    interpreter.explain_with_shap(
        processor.X_train_scaled, processor.y_train, X_test_sample, Config.N_FEATURES_TO_DISPLAY
    )

    # 7. é¡¯ç¤ºæ··æ·†çŸ©é™£çš„è©³ç´°åˆ†æ
    print("\n" + "="*70)
    print(f"ğŸ“Š æ··æ·†çŸ©é™£åˆ†æ")
    print("="*70)
    
    cm_df = pd.DataFrame(
        cm,
        index=['å¯¦éš›: ' + tn for tn in target_names],
        columns=['é æ¸¬: ' + tn for tn in target_names]
    )
    print("\næ··æ·†çŸ©é™£:")
    print(cm_df)
    
    # è¨ˆç®—æ¯å€‹é¡åˆ¥çš„ç²¾ç¢ºåº¦ã€å¬å›ç‡å’ŒF1åˆ†æ•¸
    precision = np.diag(cm) / np.sum(cm, axis=0)
    recall = np.diag(cm) / np.sum(cm, axis=1)
    f1 = 2 * (precision * recall) / (precision + recall)
    
    print("\nå„é¡åˆ¥è©³ç´°æŒ‡æ¨™:")
    metrics_df = pd.DataFrame({
        'ç²¾ç¢ºåº¦': precision,
        'å¬å›ç‡': recall,
        'F1åˆ†æ•¸': f1
    }, index=target_names)
    print(metrics_df.round(4))
    print("="*70)

    # 8. å„²å­˜é è™•ç†å·¥å…·
    print("\n" + "="*70)
    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜é è™•ç†å·¥å…·è‡³ '{Config.MODEL_DIR}' è³‡æ–™å¤¾...")
    joblib.dump(processor.scaler, os.path.join(Config.MODEL_DIR, 'exoplanet_scaler.joblib'))
    joblib.dump(processor.imputer, os.path.join(Config.MODEL_DIR, 'exoplanet_imputer.joblib'))
    joblib.dump(processor.feature_names, os.path.join(Config.MODEL_DIR, 'exoplanet_feature_names.joblib'))
    print(f"   - âœ… Scaler, Imputer, å’Œ Feature Names å·²æˆåŠŸä¿å­˜ã€‚")
    print("="*70)