# å…‰è®Šæ›²ç·šæ•¸æ“šé è¼‰ç³»çµ±

## æ¦‚è¿°

`preload_data.py` æ˜¯ç³»å¤–è¡Œæ˜Ÿé …ç›®ä¸­çš„å…‰è®Šæ›²ç·šæ•¸æ“šä¸‹è¼‰å’Œé è™•ç†å·¥å…·ã€‚è©²å·¥å…·èƒ½å¤ å¾è™•ç†éçš„ç³»å¤–è¡Œæ˜Ÿæ•¸æ“šä¸­æå–ç›®æ¨™ä¿¡æ¯ï¼Œä¸¦æ‰¹é‡ä¸‹è¼‰å°æ‡‰çš„å…‹æ™®å‹’ (Kepler) å’Œ TESS å…‰è®Šæ›²ç·šæ•¸æ“šï¼Œç‚ºå¾ŒçºŒçš„ç‰¹å¾µèƒå–å’Œæ©Ÿå™¨å­¸ç¿’æä¾›æ¨™æº–åŒ–çš„æ•¸æ“šæºã€‚

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1. æ™ºèƒ½æ•¸æ“šä¸‹è¼‰
- **å¤šæºæ”¯æŒ**: åŒæ™‚æ”¯æŒå…‹æ™®å‹’ (KOI) å’Œ TESS æ•¸æ“š
- **ä¸¦è¡Œä¸‹è¼‰**: å¤šç·šç¨‹åŒæ™‚ä¸‹è¼‰å¤šå€‹ç›®æ¨™
- **æ™ºèƒ½é‡è©¦**: è‡ªå‹•è™•ç†æå£æ–‡ä»¶å’Œç¶²è·¯éŒ¯èª¤
- **å¿«å–æ©Ÿåˆ¶**: é¿å…é‡è¤‡ä¸‹è¼‰ç›¸åŒæ•¸æ“š

### 2. æ•¸æ“šé è™•ç†
- **æ ¼å¼æ¨™æº–åŒ–**: çµ±ä¸€è¼¸å‡º CSV æ ¼å¼
- **æ™‚é–“çª—å£æˆªå–**: åŸºæ–¼å‡Œæ—¥ä¸­é»çš„æ™‚é–“çª—å£æˆªå–
- **ä¸‹æ¡æ¨£**: å¯é¸çš„æ•¸æ“šé»ä¸‹æ¡æ¨£
- **å“è³ªæ§åˆ¶**: è‡ªå‹•éæ¿¾ä½å“è³ªæ•¸æ“š

### 3. éŒ¯èª¤è™•ç†
- **æå£æ–‡ä»¶æ¸…ç†**: è‡ªå‹•æª¢æ¸¬å’Œåˆªé™¤æå£çš„ FITS æ–‡ä»¶
- **ç¶²è·¯é‡è©¦**: è™•ç†ç¶²è·¯é€£æ¥å•é¡Œ
- **ç·šç¨‹å®‰å…¨**: å¤šç·šç¨‹ç’°å¢ƒä¸‹çš„å®‰å…¨è¼¸å‡º

## ğŸ“‹ ç³»çµ±è¦æ±‚

### ä¾è³´å¥—ä»¶
```bash
pip install lightkurve pandas numpy tqdm
```

### ç¡¬é«”è¦æ±‚
- **è¨˜æ†¶é«”**: å»ºè­° 4GB+ RAM
- **å„²å­˜**: æ¯å€‹å…‰è®Šæ›²ç·šç´„ 1-10MB
- **ç¶²è·¯**: éœ€è¦ç©©å®šçš„ç¶²è·¯é€£æ¥

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬å‘½ä»¤
```bash
python preload_data.py \
    --processed_csv data/exoplanet_data_processed.csv \
    --data_dir ./lightkurve_data \
    --max_targets 100 \
    --max_workers 4
```

### åƒæ•¸èªªæ˜

| åƒæ•¸ | é¡å‹ | å¿…éœ€ | é è¨­å€¼ | èªªæ˜ |
|------|------|------|--------|------|
| `--processed_csv` | str | âœ“ | - | è™•ç†éçš„æ•¸æ“š CSV æ–‡ä»¶è·¯å¾‘ |
| `--data_dir` | str | âœ“ | - | è¼¸å‡ºæ•¸æ“šç›®éŒ„ |
| `--max_targets` | int | âœ— | 50 | æœ€å¤§è™•ç†ç›®æ¨™æ•¸ |
| `--max_workers` | int | âœ— | 4 | ä¸¦è¡Œä¸‹è¼‰ç·šç¨‹æ•¸ |
| `--window_days` | float | âœ— | None | æ™‚é–“çª—å£ï¼ˆå¤©ï¼‰ |
| `--downsample` | int | âœ— | None | ä¸‹æ¡æ¨£é»æ•¸ |
| `--retry` | int | âœ— | 1 | é‡è©¦æ¬¡æ•¸ |

### ä½¿ç”¨ç¯„ä¾‹

#### 1. åŸºæœ¬ä¸‹è¼‰
```bash
python preload_data.py \
    --processed_csv data/exoplanet_data_processed.csv \
    --data_dir ./lightkurve_data \
    --max_targets 50
```

#### 2. é«˜æ•ˆä¸¦è¡Œä¸‹è¼‰
```bash
python preload_data.py \
    --processed_csv data/exoplanet_data_processed.csv \
    --data_dir ./lightkurve_data \
    --max_targets 200 \
    --max_workers 8
```

#### 3. æ™‚é–“çª—å£æˆªå–
```bash
python preload_data.py \
    --processed_csv data/exoplanet_data_processed.csv \
    --data_dir ./lightkurve_data \
    --window_days 30 \
    --downsample 10000
```

#### 4. å¤§é‡æ•¸æ“šè™•ç†
```bash
python preload_data.py \
    --processed_csv data/exoplanet_data_processed.csv \
    --data_dir ./lightkurve_data \
    --max_targets 1000 \
    --max_workers 16 \
    --downsample 20000
```

## ğŸ”§ æ ¸å¿ƒå‡½æ•¸èªªæ˜

### æ•¸æ“šè®€å–å‡½æ•¸

#### `load_processed_data(csv_path: Path) -> pd.DataFrame`
**åŠŸèƒ½**: è®€å–è™•ç†éçš„ç³»å¤–è¡Œæ˜Ÿæ•¸æ“š
**åƒæ•¸**:
- `csv_path`: CSV æ–‡ä»¶è·¯å¾‘
**è¿”å›**: åŒ…å«æ‰€æœ‰è™•ç†å¾Œæ•¸æ“šçš„ DataFrame
**ç‰¹é»**: è‡ªå‹•è™•ç†ç·¨ç¢¼å’Œæ ¼å¼å•é¡Œ

#### `select_labeled_samples(df: pd.DataFrame, max_targets: Optional[int]) -> pd.DataFrame`
**åŠŸèƒ½**: é¸æ“‡æ¨™è¨˜çš„æ¨£æœ¬ä¸¦å»ºç«‹ç›®æ¨™åˆ—è¡¨
**åƒæ•¸**:
- `df`: åŸå§‹æ•¸æ“šæ¡†
- `max_targets`: æœ€å¤§ç›®æ¨™æ•¸ï¼ˆå¯é¸ï¼‰
**è¿”å›**: åŒ…å«å¿…è¦æ¬„ä½çš„æ¨£æœ¬ DataFrame
**ä¿ç•™æ¬„ä½**:
- `source_id`: æ•¸æ“šæº ID
- `source_telescope`: æœ›é é¡é¡å‹ (KOI/TESS)
- `disposition`: è¡Œæ˜Ÿç‹€æ…‹
- `lightcurve_id`: å…‰è®Šæ›²ç·š ID
- `period`: è»Œé“é€±æœŸ
- `transit_midpoint`: å‡Œæ—¥ä¸­é»æ™‚é–“

### å…‰è®Šæ›²ç·šä¸‹è¼‰å‡½æ•¸

#### `_download_kepler_lc(lightcurve_id: str, download_dir: Path)`
**åŠŸèƒ½**: ä¸‹è¼‰å…‹æ™®å‹’å…‰è®Šæ›²ç·š
**åƒæ•¸**:
- `lightcurve_id`: å…‹æ™®å‹’æ˜Ÿé«” ID
- `download_dir`: ä¸‹è¼‰ç›®éŒ„
**è¿”å›**: LightCurveFile å°è±¡
**ç‰¹é»**:
- ä½¿ç”¨ KIC ID æª¢ç´¢
- å„ªå…ˆé¸æ“‡ long-cadence æ•¸æ“š
- è‡ªå‹•è™•ç†å¤šå€‹å­£åº¦çš„æ•¸æ“š

#### `_download_tess_lc(lightcurve_id: str, download_dir: Path)`
**åŠŸèƒ½**: ä¸‹è¼‰ TESS å…‰è®Šæ›²ç·š
**åƒæ•¸**:
- `lightcurve_id`: TESS æ˜Ÿé«” ID
- `download_dir`: ä¸‹è¼‰ç›®éŒ„
**è¿”å›**: LightCurveFile å°è±¡
**ç‰¹é»**:
- ä½¿ç”¨ TIC ID æª¢ç´¢
- æ”¯æŒå¤šå€‹ Sector çš„æ•¸æ“š
- è‡ªå‹•è™•ç†ä¸åŒè§€æ¸¬æ¨¡å¼

#### `safe_download_lcfile(lightcurve_id: str, source_telescope: str, download_dir: Path, retries: int)`
**åŠŸèƒ½**: å®‰å…¨ä¸‹è¼‰å…‰è®Šæ›²ç·šæ–‡ä»¶ï¼ŒåŒ…å«éŒ¯èª¤è™•ç†
**åƒæ•¸**:
- `lightcurve_id`: å…‰è®Šæ›²ç·š ID
- `source_telescope`: æœ›é é¡é¡å‹
- `download_dir`: ä¸‹è¼‰ç›®éŒ„
- `retries`: é‡è©¦æ¬¡æ•¸
**è¿”å›**: LightCurveFile å°è±¡
**éŒ¯èª¤è™•ç†**:
- è‡ªå‹•æª¢æ¸¬æå£çš„ FITS æ–‡ä»¶
- æ¸…ç†æå£æ–‡ä»¶å¾Œé‡è©¦
- è™•ç†ç¶²è·¯é€£æ¥å•é¡Œ

### æ•¸æ“šè™•ç†å‡½æ•¸

#### `lcfile_to_lightcurve(lcf) -> lk.LightCurve`
**åŠŸèƒ½**: å¾ LightCurveFile æå–å¯ç”¨çš„å…‰è®Šæ›²ç·š
**åƒæ•¸**:
- `lcf`: LightCurveFile å°è±¡
**è¿”å›**: è™•ç†å¾Œçš„ LightCurve å°è±¡
**è™•ç†æµç¨‹**:
1. å„ªå…ˆé¸æ“‡ PDCSAP_FLUXï¼ˆå»é™¤ç³»çµ±æ€§è¶¨å‹¢ï¼‰
2. å›é€€åˆ° SAP_FLUXï¼ˆåŸå§‹å…‰åº¦ï¼‰
3. ç§»é™¤ NaN å€¼
4. å¯é¸çš„å¹³å¦åŒ–è™•ç†
5. å¯é¸çš„æ­£è¦åŒ–è™•ç†

#### `apply_time_window_and_downsample(lc: lk.LightCurve, transit_midpoint: Optional[float], window_days: Optional[float], downsample: Optional[int]) -> lk.LightCurve`
**åŠŸèƒ½**: æ‡‰ç”¨æ™‚é–“çª—å£æˆªå–å’Œä¸‹æ¡æ¨£
**åƒæ•¸**:
- `lc`: åŸå§‹å…‰è®Šæ›²ç·š
- `transit_midpoint`: å‡Œæ—¥ä¸­é»æ™‚é–“
- `window_days`: æ™‚é–“çª—å£ï¼ˆå¤©ï¼‰
- `downsample`: ä¸‹æ¡æ¨£é»æ•¸
**è¿”å›**: è™•ç†å¾Œçš„å…‰è®Šæ›²ç·š
**è™•ç†é‚è¼¯**:
- æ™‚é–“çª—å£: `[transit_midpoint - window_days, transit_midpoint + window_days]`
- ä¸‹æ¡æ¨£: å‡å‹»é¸æ“‡æŒ‡å®šæ•¸é‡çš„æ•¸æ“šé»

#### `save_lightcurve_csv(lc: lk.LightCurve, out_csv: Path)`
**åŠŸèƒ½**: å°‡å…‰è®Šæ›²ç·šä¿å­˜ç‚º CSV æ ¼å¼
**åƒæ•¸**:
- `lc`: LightCurve å°è±¡
- `out_csv`: è¼¸å‡º CSV æ–‡ä»¶è·¯å¾‘
**è¼¸å‡ºæ ¼å¼**:
- æ¬„ä½: `time`, `flux`
- ç·¨ç¢¼: UTF-8
- æ ¼å¼: CSV (ç„¡ç´¢å¼•)

### æ‰¹é‡è™•ç†å‡½æ•¸

#### `download_one_target(source_id: str, lightcurve_id: str, source_telescope: str, out_dir: Path, transit_midpoint: Optional[float], window_days: Optional[float], downsample: Optional[int], retry: int) -> str`
**åŠŸèƒ½**: ä¸‹è¼‰å–®ä¸€ç›®æ¨™çš„å®Œæ•´æµç¨‹
**åƒæ•¸**:
- `source_id`: æ•¸æ“šæº ID
- `lightcurve_id`: å…‰è®Šæ›²ç·š ID
- `source_telescope`: æœ›é é¡é¡å‹
- `out_dir`: è¼¸å‡ºç›®éŒ„
- `transit_midpoint`: å‡Œæ—¥ä¸­é»æ™‚é–“
- `window_days`: æ™‚é–“çª—å£
- `downsample`: ä¸‹æ¡æ¨£é»æ•¸
- `retry`: é‡è©¦æ¬¡æ•¸
**è¿”å›**: æˆåŠŸè™•ç†çš„ source_id
**è¼¸å‡ºæ–‡ä»¶**: `{source_telescope}_{lightcurve_id}.csv`

#### `bulk_download(targets: List[Dict[str, Any]], data_dir: str, max_workers: int, window_days: Optional[float], downsample: Optional[int], retry: int) -> Tuple[List[str], List[str]]`
**åŠŸèƒ½**: æ‰¹é‡ä¸¦è¡Œä¸‹è¼‰å¤šå€‹ç›®æ¨™
**åƒæ•¸**:
- `targets`: ç›®æ¨™åˆ—è¡¨
- `data_dir`: æ•¸æ“šç›®éŒ„
- `max_workers`: æœ€å¤§ç·šç¨‹æ•¸
- `window_days`: æ™‚é–“çª—å£
- `downsample`: ä¸‹æ¡æ¨£é»æ•¸
- `retry`: é‡è©¦æ¬¡æ•¸
**è¿”å›**: (æˆåŠŸåˆ—è¡¨, å¤±æ•—åˆ—è¡¨)
**ç‰¹é»**:
- ä½¿ç”¨ ThreadPoolExecutor ä¸¦è¡Œè™•ç†
- ç·šç¨‹å®‰å…¨çš„é€²åº¦è¼¸å‡º
- è‡ªå‹•éŒ¯èª¤è™•ç†å’Œé‡è©¦

## ğŸ“Š æ•¸æ“šè™•ç†æµç¨‹

### 1. æ•¸æ“šæº–å‚™éšæ®µ
```python
# è®€å–è™•ç†éçš„æ•¸æ“š
df = load_processed_data(processed_csv)

# é¸æ“‡æ¨™è¨˜æ¨£æœ¬
sub = select_labeled_samples(df, max_targets)

# å»ºç«‹ç›®æ¨™åˆ—è¡¨
targets = []
for _, row in sub.iterrows():
    target = {
        "source_id": row["source_id"],
        "lightcurve_id": str(row["lightcurve_id"]),
        "source_telescope": row["source_telescope"],
        "transit_midpoint": float(row["transit_midpoint"]) if pd.notna(row["transit_midpoint"]) else None
    }
    targets.append(target)
```

### 2. ä¸¦è¡Œä¸‹è¼‰éšæ®µ
```python
# ä½¿ç”¨ç·šç¨‹æ± ä¸¦è¡Œä¸‹è¼‰
with ThreadPoolExecutor(max_workers=max_workers) as executor:
    futures = {}
    for target in targets:
        future = executor.submit(
            download_one_target,
            target["source_id"],
            target["lightcurve_id"],
            target["source_telescope"],
            out_dir,
            target["transit_midpoint"],
            window_days,
            downsample,
            retry
        )
        futures[future] = target["source_id"]
```

### 3. çµæœè™•ç†éšæ®µ
```python
# æ”¶é›†æˆåŠŸå’Œå¤±æ•—çš„çµæœ
ok, fail = [], []
for future in as_completed(futures):
    source_id = futures[future]
    try:
        future.result()
        ok.append(source_id)
    except Exception as e:
        fail.append(source_id)
```

## ğŸ› ï¸ éŒ¯èª¤è™•ç†æ©Ÿåˆ¶

### 1. æå£æ–‡ä»¶è™•ç†
```python
def _find_bad_fits_path_from_error(msg: str) -> Optional[Path]:
    """å¾éŒ¯èª¤è¨Šæ¯ä¸­æ‰¾å‡ºæå£çš„ FITS æ–‡ä»¶è·¯å¾‘"""
    patterns = [
        r"(/[^\\\s]+?\.fits)",  # åŸºæœ¬ .fits æ–‡ä»¶
        r"(lightkurve_data/mastDownload/[^\\\s]+?\.fits)",  # å®Œæ•´è·¯å¾‘
        r"(mastDownload/[^\\\s]+?\.fits)"  # ç›¸å°è·¯å¾‘
    ]
    
    for pattern in patterns:
        match = re.search(pattern, msg)
        if match:
            path = Path(match.group(1))
            if path.exists():
                return path
    return None
```

### 2. è‡ªå‹•é‡è©¦æ©Ÿåˆ¶
```python
def safe_download_lcfile(lightcurve_id: str, source_telescope: str, download_dir: Path, retries: int):
    """å®‰å…¨ä¸‹è¼‰ï¼ŒåŒ…å«é‡è©¦æ©Ÿåˆ¶"""
    try:
        # å˜—è©¦ä¸‹è¼‰
        return _download_lc(lightcurve_id, source_telescope, download_dir)
    except Exception as e:
        if retries <= 0:
            raise
        
        # æ¸…ç†æå£æ–‡ä»¶
        bad_file = _find_bad_fits_path_from_error(str(e))
        if bad_file and bad_file.exists():
            bad_file.unlink()
            # æ¸…ç†ç©ºç›®éŒ„
            parent_dir = bad_file.parent
            if parent_dir.exists() and not any(parent_dir.iterdir()):
                parent_dir.rmdir()
        
        # é‡è©¦
        return safe_download_lcfile(lightcurve_id, source_telescope, download_dir, retries - 1)
```

### 3. ç·šç¨‹å®‰å…¨è¼¸å‡º
```python
# ç·šç¨‹å®‰å…¨çš„è¼¸å‡ºé–
print_lock = threading.Lock()

def safe_print(*args, **kwargs):
    """ç·šç¨‹å®‰å…¨çš„ print å‡½æ•¸"""
    with print_lock:
        try:
            print(*args, **kwargs)
        except (ValueError, OSError):
            # å¦‚æœ stdout è¢«é—œé–‰ï¼Œå¿½ç•¥éŒ¯èª¤
            pass
```

## ğŸ“ˆ æ€§èƒ½å„ªåŒ–

### 1. ä¸¦è¡Œè™•ç†
- **å¤šç·šç¨‹ä¸‹è¼‰**: åŒæ™‚ä¸‹è¼‰å¤šå€‹ç›®æ¨™
- **ç·šç¨‹æ± ç®¡ç†**: è‡ªå‹•ç®¡ç†ç·šç¨‹ç”Ÿå‘½é€±æœŸ
- **è² è¼‰å¹³è¡¡**: æ ¹æ“šç³»çµ±è³‡æºèª¿æ•´ç·šç¨‹æ•¸

### 2. è¨˜æ†¶é«”å„ªåŒ–
- **æµå¼è™•ç†**: é€å€‹è™•ç†ç›®æ¨™ï¼Œé¿å…å¤§é‡æ•¸æ“šè¼‰å…¥è¨˜æ†¶é«”
- **åŠæ™‚æ¸…ç†**: è™•ç†å®Œæˆå¾Œç«‹å³é‡‹æ”¾è³‡æº
- **å¿«å–ç­–ç•¥**: æ™ºèƒ½å¿«å–ä¸‹è¼‰çš„æ•¸æ“š

### 3. ç¶²è·¯å„ªåŒ–
- **é‡è©¦æ©Ÿåˆ¶**: è™•ç†ç¶²è·¯ä¸ç©©å®šå•é¡Œ
- **éŒ¯èª¤æ¢å¾©**: è‡ªå‹•æ¸…ç†æå£æ–‡ä»¶
- **é€²åº¦è¿½è¹¤**: å¯¦æ™‚é¡¯ç¤ºä¸‹è¼‰é€²åº¦

## ğŸ“ è¼¸å‡ºæ–‡ä»¶æ ¼å¼

### å…‰è®Šæ›²ç·š CSV æ ¼å¼
```csv
time,flux
2454833.0,1.000000
2454833.5,0.999500
2454834.0,1.000200
...
```

### æ–‡ä»¶å‘½åè¦å‰‡
- **å…‹æ™®å‹’æ•¸æ“š**: `KOI_{lightcurve_id}.csv`
- **TESS æ•¸æ“š**: `TESS_{lightcurve_id}.csv`

### ç›®éŒ„çµæ§‹
```
lightkurve_data/
â”œâ”€â”€ KOI_123456.csv
â”œâ”€â”€ KOI_123457.csv
â”œâ”€â”€ TESS_987654.csv
â”œâ”€â”€ TESS_987655.csv
â””â”€â”€ mastDownload/  # LightKurve å¿«å–ç›®éŒ„
    â”œâ”€â”€ Kepler/
    â””â”€â”€ TESS/
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### 1. ä¸‹è¼‰å¤±æ•—
```bash
# éŒ¯èª¤: FileNotFoundError: No Kepler LCF for KIC xxx
# è§£æ±º: æª¢æŸ¥æ˜Ÿé«” ID æ˜¯å¦æ­£ç¢ºï¼Œæˆ–è©²æ˜Ÿé«”æ˜¯å¦åœ¨å…‹æ™®å‹’è§€æ¸¬ç¯„åœå…§
```

#### 2. è¨˜æ†¶é«”ä¸è¶³
```bash
# éŒ¯èª¤: MemoryError
# è§£æ±º: æ¸›å°‘ max_workers åƒæ•¸ï¼Œæˆ–å¢åŠ ç³»çµ±è¨˜æ†¶é«”
```

#### 3. ç¶²è·¯å•é¡Œ
```bash
# éŒ¯èª¤: ConnectionError
# è§£æ±º: æª¢æŸ¥ç¶²è·¯é€£æ¥ï¼Œæˆ–ä½¿ç”¨ --retry å¢åŠ é‡è©¦æ¬¡æ•¸
```

### èª¿è©¦æŠ€å·§

#### 1. å•Ÿç”¨è©³ç´°è¼¸å‡º
```python
# åœ¨å‡½æ•¸ä¸­æ·»åŠ èª¿è©¦ä¿¡æ¯
safe_print(f"æ­£åœ¨ä¸‹è¼‰ {source_telescope} {lightcurve_id}")
safe_print(f"ç›®æ¨™ç›®éŒ„: {out_dir}")
```

#### 2. æª¢æŸ¥æ•¸æ“šå“è³ª
```python
# æª¢æŸ¥ä¸‹è¼‰çš„æ•¸æ“š
df = pd.read_csv(csv_path)
print(f"æ•¸æ“šé»æ•¸: {len(df)}")
print(f"æ™‚é–“ç¯„åœ: {df['time'].min()} - {df['time'].max()}")
print(f"æµé‡ç¯„åœ: {df['flux'].min()} - {df['flux'].max()}")
```

#### 3. é€æ­¥æ¸¬è©¦
```bash
# å…ˆæ¸¬è©¦å°‘é‡æ¨£æœ¬
python preload_data.py --max_targets 5
```

## ğŸš€ é€²éšä½¿ç”¨

### 1. è‡ªå®šç¾©æ™‚é–“çª—å£
```python
# æ ¹æ“šè»Œé“é€±æœŸèª¿æ•´æ™‚é–“çª—å£
window_days = period * 2  # 2 å€‹è»Œé“é€±æœŸ
```

### 2. æ™ºèƒ½ä¸‹æ¡æ¨£
```python
# æ ¹æ“šæ•¸æ“šå¯†åº¦èª¿æ•´ä¸‹æ¡æ¨£
if len(lc.time) > 50000:
    downsample = 20000
elif len(lc.time) > 10000:
    downsample = 5000
else:
    downsample = None
```

### 3. æ‰¹é‡è™•ç†è…³æœ¬
```bash
#!/bin/bash
# åˆ†æ‰¹è™•ç†å¤§é‡æ•¸æ“š
for batch in {1..10}; do
    python preload_data.py \
        --processed_csv data/exoplanet_data_processed.csv \
        --data_dir ./lightkurve_data_batch_$batch \
        --max_targets 100 \
        --max_workers 8
done
```

## ğŸ“š ç›¸é—œå·¥å…·

### èˆ‡å…¶ä»–çµ„ä»¶çš„æ•´åˆ

#### 1. æ•¸æ“šé è™•ç†
```bash
# å…ˆé‹è¡Œæ•¸æ“šé è™•ç†
cd data/
python data_preprocessing_augment.py

# å†ä¸‹è¼‰å…‰è®Šæ›²ç·š
python ../preload_data.py \
    --processed_csv exoplanet_data_processed.csv \
    --data_dir ../lightkurve_data
```

#### 2. ç‰¹å¾µèƒå–
```bash
# ä½¿ç”¨ä¸‹è¼‰çš„å…‰è®Šæ›²ç·šé€²è¡Œç‰¹å¾µèƒå–
python tsfresh_LightGBM.py \
    --processed_csv data/exoplanet_data_processed.csv \
    --out_dir ./results \
    --lc_dir ./lightkurve_data \
    --offline
```

### æ•¸æ“šå“è³ªæª¢æŸ¥
```python
# æª¢æŸ¥ä¸‹è¼‰çš„æ•¸æ“šå“è³ª
import pandas as pd
import numpy as np

def check_lightcurve_quality(csv_path):
    df = pd.read_csv(csv_path)
    
    # åŸºæœ¬çµ±è¨ˆ
    print(f"æ•¸æ“šé»æ•¸: {len(df)}")
    print(f"æ™‚é–“ç¯„åœ: {df['time'].max() - df['time'].min():.2f} å¤©")
    print(f"æµé‡æ¨™æº–å·®: {df['flux'].std():.6f}")
    
    # æª¢æŸ¥ç•°å¸¸å€¼
    flux_std = df['flux'].std()
    flux_mean = df['flux'].mean()
    outliers = np.abs(df['flux'] - flux_mean) > 3 * flux_std
    print(f"ç•°å¸¸å€¼æ•¸é‡: {outliers.sum()}")
    
    return len(df) > 100 and outliers.sum() < len(df) * 0.1
```

---

**æ³¨æ„**: æœ¬å·¥å…·éœ€è¦ç©©å®šçš„ç¶²è·¯é€£æ¥å’Œå……è¶³çš„å„²å­˜ç©ºé–“ã€‚å»ºè­°åœ¨ç¶²è·¯æ¢ä»¶è‰¯å¥½çš„ç’°å¢ƒä¸‹é‹è¡Œï¼Œä¸¦å®šæœŸæª¢æŸ¥ä¸‹è¼‰çš„æ•¸æ“šå“è³ªã€‚
