import pandas as pd
import numpy as np
import joblib
import warnings
import os
import json
import io
import sys
import traceback
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from lightgbm import LGBMClassifier

warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)

def run_training_pipeline(model_choice: str, custom_params: dict, input_csv_path: str):
    """
    The main training pipeline function, callable from other scripts like app.py.
    """
    old_stdout = sys.stdout
    sys.stdout = captured_output = io.StringIO()
    
    trained_artifacts = {
        "model": None,
        "imputer": None,
        "scaler": None,
        "feature_names": None
    }
    output_model_path = None
    # ### ä¿®æ”¹é–‹å§‹ ###ï¼šåˆå§‹åŒ–æ··æ·†çŸ©é™£èˆ‡åˆ†é¡å ±å‘Šè®Šæ•¸
    confusion_matrix_data = None
    classification_report_data = None
    accuracy_value = None
    # ### ä¿®æ”¹çµæŸ ###

    try:
        print(f"--- é–‹å§‹ç·šä¸Šè¨“ç·´æµç¨‹ï¼š{model_choice} ---")
        print(f"ä½¿ç”¨è³‡æ–™é›†: {input_csv_path}")
        print(f"è‡ªè¨‚è¶…åƒæ•¸: {json.dumps(custom_params, indent=2)}")

        # --- 1. Data Loading and Preparation ---
        df = pd.read_csv(input_csv_path, dtype={'source_id': str})
        df.replace([np.inf, -np.inf], np.nan, inplace=True)
        
        # ä½¿ç”¨æ‰€æœ‰æ¨™ç±¤é€²è¡Œä¸‰å…ƒåˆ†é¡
        disposition_map = {
            'CONFIRMED': 2,
            'CANDIDATE': 1,
            'FALSE POSITIVE': 0
        }
        training_df = df[df['disposition'].isin(disposition_map.keys())].copy()
        if training_df.empty:
            raise ValueError("æä¾›çš„è³‡æ–™é›†ä¸­æ²’æœ‰å¯ç”¨çš„æ¨™ç±¤è³‡æ–™ã€‚")

        # é¡¯ç¤ºé¡åˆ¥åˆ†å¸ƒ
        print("\né¡åˆ¥åˆ†å¸ƒï¼š")
        print(training_df['disposition'].value_counts())
        
        training_df['disposition'] = training_df['disposition'].map(disposition_map)
        
        if 'source_telescope' in training_df.columns:
            training_df = pd.get_dummies(training_df, columns=['source_telescope'], drop_first=True)
        
        X = training_df.drop(columns=['disposition', 'source_id'])
        y = training_df['disposition']
        feature_names = X.columns.tolist()

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, stratify=y
        )

        imputer = SimpleImputer(strategy='median')
        X_train_imputed = imputer.fit_transform(X_train)
        X_test_imputed = imputer.transform(X_test)

        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train_imputed)
        X_test_scaled = scaler.transform(X_test_imputed)
        print("âœ… è³‡æ–™è¼‰å…¥èˆ‡é è™•ç†å®Œæˆã€‚")

        # --- 2. Model Configuration ---
        MODELS_CONFIG = {
            "LogisticRegression": {
                "model": LogisticRegression,
                "params": {
                    "random_state": 42,
                    "class_weight": "balanced",
                    "max_iter": 5000,
                    "multi_class": "multinomial",  # å¤šåˆ†é¡è¨­ç½®
                    "solver": "lbfgs"
                }
            },
            "RandomForest": {
                "model": RandomForestClassifier,
                "params": {
                    "random_state": 42,
                    "class_weight": "balanced",
                    "n_estimators": 1000,
                    "max_depth": 15
                }
            },
            "GradientBoosting": {
                "model": GradientBoostingClassifier,
                "params": {
                    "random_state": 42,
                    "n_estimators": 1000,
                    "learning_rate": 0.05,
                    "max_depth": 7
                }
            },
            "LightGBM": {
                "model": LGBMClassifier,
                "params": {
                    "random_state": 42,
                    "verbosity": -1,
                    "class_weight": "balanced",
                    "n_estimators": 1000,
                    "learning_rate": 0.05,
                    "num_leaves": 50,
                    "max_depth": 7,
                    "objective": "multiclass",  # å¤šåˆ†é¡è¨­ç½®
                    "num_class": 3  # ä¸‰å€‹é¡åˆ¥
                }
            }
        }

        if model_choice not in MODELS_CONFIG:
            raise ValueError(f"é¸æ“‡çš„æ¨¡å‹ '{model_choice}' ä¸è¢«æ”¯æ´ã€‚")

        model_config = MODELS_CONFIG[model_choice]
        model_config["params"].update(custom_params)
        model = model_config["model"](**model_config["params"])
        print(f"\nâœ… æ¨¡å‹ '{model_choice}' å¯¦ä¾‹åŒ–æˆåŠŸï¼Œä½¿ç”¨æœ€çµ‚åƒæ•¸: {model.get_params()}")

        # --- 3. Training ---
        print("\nğŸš€ é–‹å§‹è¨“ç·´æ¨¡å‹...")
        model.fit(X_train_scaled, y_train)
        print("âœ… æ¨¡å‹è¨“ç·´å®Œæˆã€‚")
        
        # --- 4. Evaluation and Reporting ---
        print("\nğŸ“‹ ç”¢ç”Ÿæ¨¡å‹åœ¨æ¸¬è©¦é›†ä¸Šçš„è¡¨ç¾å ±å‘Š...")
        target_names = ['FALSE POSITIVE', 'CANDIDATE', 'CONFIRMED']
        y_pred = model.predict(X_test_scaled)
        report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)
        cm = confusion_matrix(y_test, y_pred)
        
        # å°‡æ··æ·†çŸ©é™£æ‰“åŒ…æˆå­—å…¸ä»¥ä¾›å›å‚³
        confusion_matrix_data = {
            "matrix": cm.tolist(),  # å°‡ numpy array è½‰ç‚º python list
            "labels": target_names
        }
        print("âœ… æ··æ·†çŸ©é™£è³‡æ–™å·²ç”¢ç”Ÿã€‚")

        # æ‰“åŒ…åˆ†é¡å ±å‘Šèˆ‡æ•´é«”æº–ç¢ºåº¦ä¾›å›å‚³
        classification_report_data = report
        accuracy_value = float(report.get('accuracy', 0.0))

        # è¨ˆç®—æ¯å€‹é¡åˆ¥çš„æ€§èƒ½æŒ‡æ¨™
        print("\n=== åˆ†é¡å ±å‘Š ===")
        for class_name in target_names:
            metrics = report[class_name]
            print(f"\n{class_name}:")
            print(f"  ç²¾ç¢ºåº¦: {metrics['precision']:.3f}")
            print(f"  å¬å›ç‡: {metrics['recall']:.3f}")
            print(f"  F1åˆ†æ•¸: {metrics['f1-score']:.3f}")
        
        print(f"\næ•´é«”æº–ç¢ºåº¦: {report['accuracy']:.3f}")
        print(f"Macro avg F1: {report['macro avg']['f1-score']:.3f}")
        print(f"Weighted avg F1: {report['weighted avg']['f1-score']:.3f}")

        print("\n=== æ··æ·†çŸ©é™£ ===")
        print("é æ¸¬é¡åˆ¥:")
        print(f"{'å¯¦éš›é¡åˆ¥':<15} | {'FALSE POSITIVE':<15} | {'CANDIDATE':<15} | {'CONFIRMED':<15}")
        print("-" * 65)
        for i, class_name in enumerate(target_names):
            row = [f"{class_name:<15}"]
            row.extend([f"{cm[i][j]:<15}" for j in range(3)])
            print(" | ".join(row))
        
        # --- 5. Saving Artifacts (for potential debug) and preparing for return ---
        model_dir = "temp_models"
        os.makedirs(model_dir, exist_ok=True)
        
        model_name_key = model_choice.lower()
        output_model_path = os.path.join(model_dir, f"{model_name_key}_model.joblib")
        joblib.dump(model, output_model_path)
        print(f"\nğŸ’¾ (Debug) æ¨¡å‹å‰¯æœ¬å·²å„²å­˜è‡³: {output_model_path}")
        
        trained_artifacts["model"] = model
        trained_artifacts["imputer"] = imputer
        trained_artifacts["scaler"] = scaler
        trained_artifacts["feature_names"] = feature_names
        
    except Exception as e:
        print("\n" + "="*50)
        print(f"âŒ è¨“ç·´æµç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        traceback.print_exc(file=sys.stdout)
        print("="*50)

    finally:
        sys.stdout = old_stdout

    # ### ä¿®æ”¹é–‹å§‹ ###ï¼šå›å‚³ 6 å€‹é …ç›®ï¼ŒåŒ…å«æ‰“åŒ…å¥½çš„æ··æ·†çŸ©é™£èˆ‡åˆ†é¡å ±å‘Šã€æº–ç¢ºåº¦
    return output_model_path, captured_output.getvalue(), trained_artifacts, confusion_matrix_data, classification_report_data, accuracy_value
    # ### ä¿®æ”¹çµæŸ ###